---
title: "Labs 3 & 4: Linear Regression and `ggplot2`"
subtitle: "Part 1: Background"
author: "Connor Wiegand"
format:
  html:
    theme: 
      - flatly
      - ../lab-style.scss
    toc: true
    toc-depth: 3
    execute: 
      # eval: false
      warning: false
      error: false
    embed-resources: true
    # html-math-method: mathjax

knitr: 
   opts_chunk: 
      class-output: code-out
      class-error: err-out
      class-message: msg-out

editor:
   render-on-save: true
---

Please review this on your own. It's mainly supposed to give you some background with linear regression and data visualization in R. 

## Linear Regression

In R, OLS in it's simplest form is achieved via the `lm` function. There are three core functions that we want to talk about today:

- __`lm`__: 
  - *Description*: Stands for "linear model." It is used to fit linear models to data. The function calculates the coefficients of a linear equation, involving one or multiple predictors that best predict the outcome (dependent variable). The LHS is separated from the RHS by a `~`, and you don't need to include an error term.
    - [Ex.]{.ex}: `model = lm(y ~ x + z, data = data)`
  - **Note**: you can transform variables from within the `lm` call.
    - e.g. `lm(log(y) ~ x^2 + factor(z))`
    - Make sure you aren't taking, e.g., `log(0)`, or R will get mad. In general, make sure your types are correct and inputs are valid

- __`resid`__: 
  - *Description*: Extracts the residuals from a model. Residuals represent the difference between the observed value and the value predicted by the model.
    - [Ex.]{.ex}: `model_residuals = resid(model)`

- __`predict`__: 
  - *Description*: Given a model and new data, this function produces predicted values based on the model's coefficients. It's often used to see how well a model performs on new, unseen data or to predict outcomes for specific input values.
    - [Ex.]{.ex}: `predicted_values = predict(model, newdata = new_data)`


Understanding these three functions will serve as a solid foundation for conducting regression analyses in R.

### Data Generating Process (DGP)

For the following examples, we'll generate some data:

```{r}
#| message: false
# Load the tidyverse
pacman::p_load(tidyverse, broom)
# Set random seed to ensure results are consistent
set.seed(42)

# Generating data
  # Number of observations
  n = 200  
  # Years of education as random variable, mean 12 years, standard deviation 2 years
  years_of_education = rnorm(n, mean=12, sd=2)
  # Income as a random variable
  income = 5000 + 2000*years_of_education + rnorm(n, mean=0, sd=500 + 250*years_of_education)

# Create a tibble
tbl = tibble(years_of_education, income)
```

### Simple Linear Regression

- Here is the formula that describes a standard wage regression.

$$
\text{Income}_i = \alpha + \beta \; \text{YearsEdu}_i + \varepsilon_i
$$

- Using the `lm` function, let's run a regression of `income` on `years_of_education`. We will assign this linear model to a variable called `model`.  

```{r}
model = lm(income ~ years_of_education, data = tbl)
```

### Model Summary

- Now, let's extract and interpret the coefficients of the regression using the `broom` package function `tidy`

```{r}
tidy(model)
```

*What does the coefficient of `years_of_education` tell you about the relationship between education and income?*

- [For each additional year of education, there is an associated increase in income by \$1865]{.darkgreen}

*Are the coefficients statistically significant at the 5% level? Provide evidence for your answer.*

- [Yes, we can reject the null hypothesis that year of education has no correlation with income since the p value is $3.65e-34$ which is $< 0.05$]{.darkgreen}

### Residuals

A simple, not so scientific way to check for heteroskedasticity is to plot the residuals across $x$ (e.g. years of education)

```{r}
model_resid = resid(model)

plot(tbl$years_of_education, model_resid, 
     xlab="Years of Education", ylab="Residuals", 
     main="Residuals vs Years of Education")
```


### Predictions

- Using the `predict` function, let's estimate the income of an individual with 10, 14, and 18 years of education.   

```{r}
new_data = tibble(years_of_education = c(10, 14, 18))
predicted_income = predict(model, newdata = new_data)
predicted_income
```

------

## `ggplot2`

Visualization is one of the most important tools for every data scientist and economist. Data visualization in R is primarily done in the tidyverse's `ggplot2` package. `ggplot2` calls can be thought of as having four main components:

- The data (usually `tidy`)
- A call to `ggplot`
- Some geometric objects^[which we can call a **_geoms_**, for short], specified with _aesthetic mappings_
- Some 'option' functions

Hence, a `ggplot` call often takes the following form 

```R
<data> %>% 
  ggplot2() +
  <geom 1> +
  ...
  <geom n> +
  <option 1> +
  ...
  <option m>
```

:::{.callout-important}
Notice that we use `+` to chain together calls after calling `ggplot`. This is in contrast to other tidyverse chaining, which primarily uses the pipe operator (`%>%`).
:::

Going through the entirey of ggplot2 would take an entire book (which you can obtain on your own). Instead, let's go through some key functions and features of `ggplot2`. When in doubt, keep the following resources handy:

  - Official `ggplot2` [tidyverse page](ggplot2.tidyverse.org) 
  - `ggplot2` [cheatsheet](https://rstudio.github.io/cheatsheets/html/data-visualization.html) 
  - [R Graph Gallery](https://r-graph-gallery.com/ggplot2-package.html)
  - Official `ggplot2` [book](https://ggplot2-book.org/)
  - `ggplot2` ["Cookbook"](https://r-graphics.org/)

### `aes` mappings

- Each `geom_*` can take (and often demand) that one of its arguments be an aesthetic mapping, or `aes()` function

- The `aes` call tells the geometric object what variables should be mapped to `ggplot` parameters

- You can supply an `aes` call to the `ggplot()` call, and all subsequent `geoms` will take use it (unless a different one is specifically provided)

- Similarly, if you don't supply an `aes` call to `ggplot`, then each `geom` much have an `aes` call

  - There are a few exceptions to this

  - In orther words, `geoms` will not look at eachother's mappings

`aes` calls are **mappings**, and add real "stuff" to your plot. We will see an example of this in the other document, but you often need to be careful about putting options in `aes()` calls vs just in the `geom` calls


### Key `geoms`

- `geom_point`
  - scatterplots, individual points
- `geom_line` + `geom_abline`
  - lines, in terms of start/end points or slope/intercept form (respectively)
- `geom_bar`/`geom_col`
  - histograms, bar charts
  - See also: `geom_histogram`
- `geom_text` 
  - textual annotations
  - See also: `annotate`
- `geom_smooth`
  - Drawing curves or lines through data using pre-built methods

### Color Scales

- You can adjust colors and some other `aes` options using various commands of the form `scale_<aes>_<type>`
  - In this context, `<aes>` is usally either `color` or `fill`
  - `<type>` is usually one of `continuous`, `discrete`, or `manual`, depending on your data

- For instance:
  - `scale_color_manual`
  - `scale_fill_continuous`
  - `scale_color_discrete`

- These `scale_*_*` functions are a bit tricky if you're still getting the hang of `ggplot`
- Which function to use and which arguments to pass often depend on use case
- I won't go into these functions for now, but we can chat about them if you want

### Key Option functions

- `labs` 
  - plot labels
  - see also: `xlab` and `ylab`
- `theme_<theme>`
  - for instance, `theme_dark()`
  - doesn't typically need inputs
  - see [this reference I use](https://r-charts.com/ggplot2/themes/) 
- `theme`
  - This is confusing: not to be confused with `theme_<theme>`
  - Think of this as (mostly) "other" adjustments, such as where (and whether) to put legend, x-axis, etc.  


